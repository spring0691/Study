from bayes_opt import BayesianOptimization

def black_box_function(x,y):
    return -x **2 - (y - 1) ** 2 + 1    
# **2 제곱해주겠다  - x^2 - (y -1)^2 + 1이란 뜻.

pbounds = { 'x' : (2,4),'y':(-3,3) }

optimizer = BayesianOptimization(
    f = black_box_function,     # f에 통상적으로 모델을 넣고
    pbounds= pbounds,           # pbounds에 파라미터를 넣어서 모델돌린다.
    random_state=66
)

optimizer.maximize(
    init_points=2,
    n_iter=15
)
'''  
이런식으로 찾아준다.   가우시안 무슨 방식으로 값을 찾아간다. 경사하강법이랑 다른가보다.
인공지능이 아니라 그냥 알고리즘이다. 경사하강법도 알고리즘인데 가우시안 방법 또한 다른 알고리즘인데
성능이 상당히 좋다.
|   iter    |  target   |     x     |     y     |
-------------------------------------------------
|  1        | -14.56    |  2.309    | -2.198    |
|  2        | -6.433    |  2.725    |  1.075    |
|  3        | -14.75    |  3.369    | -1.097    |
|  4        | -6.331    |  2.489    |  2.065    |
|  5        | -19.0     |  4.0      |  3.0      |
|  6        | -3.117    |  2.0      |  1.341    |
|  7        | -3.634    |  2.0      |  0.2036   |
|  8        | -7.0      |  2.0      |  3.0      |
|  9        | -3.053    |  2.0      |  0.7695   |
|  10       | -3.727    |  2.0      |  1.853    |
|  11       | -3.001    |  2.0      |  1.035    |
|  12       | -3.002    |  2.0      |  0.9516   |
|  13       | -3.004    |  2.0      |  1.062    |
|  14       | -3.001    |  2.0      |  0.9753   |
|  15       | -3.0      |  2.0      |  0.9868   |
|  16       | -3.0      |  2.0      |  1.017    |
|  17       | -3.001    |  2.0      |  0.9752   |
=================================================
'''
