PCA는 차원을 축소시키는 개념이고 Feature_importance는 각 칼럼을 일단 한번 돌려보고
칼럼들이 y값에 미치는 영향을 %로 보여주는 형식이다. PCA는 fit이 들어가지않는다 비지도학습과 유사하다

PCA가 근데 Feature_importance보다 더 정확성이 우위에 있다고 한다.

LDA -> PCA의 진화 버전. PCA가 x값만 가지고 차원을 축소시켜주는 개념이었다면, LDA는 y값까지 계산하면서 차원을 축소시켜준다.
따라서 PCA보다성능이 좋고, y값을 포함하여 차원축소하기때문에 x가 조금 더 정교하게 자리를 찾아간다.